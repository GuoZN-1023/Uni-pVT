expert_col: 'no'
experts:
  critical:
    activation: relu
    dropout: 0.05
    hidden_layers:
    - 512
    - 256
    - 128
  extra:
    activation: relu
    dropout: 0.05
    hidden_layers:
    - 512
    - 256
    - 128
  gas:
    activation: relu
    dropout: 0.05
    hidden_layers:
    - 256
    - 128
    - 64
  liquid:
    activation: relu
    dropout: 0.05
    hidden_layers:
    - 256
    - 128
    - 64
gate:
  activation: relu
  dropout: 0.05
  hidden_layers:
  - 128
  - 64
loss:
  lambda_nonneg: 0.06
  lambda_smooth: 0.03
model:
  input_dim: 8
paths:
  data: data/Water.csv
  save_dir: results/2025-11-21_22-18-49
  scaler: results/2025-11-21_22-18-49/scaler.pkl
target_col: Z (-)
training:
  batch_size: 128
  early_stopping_patience: 20
  epochs: 200
  learning_rate: 0.0001
  pretrain_epochs: 100
