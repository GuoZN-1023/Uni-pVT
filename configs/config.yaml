experts:
  gas:
    hidden_layers: [256, 128, 64]
    activation: relu
    dropout: 0.05
  liquid:
    hidden_layers: [256, 128, 64]
    activation: relu
    dropout: 0.05
  critical:
    hidden_layers: [512, 256, 128]
    activation: relu
    dropout: 0.05
  extra:              # 第四个专家
    hidden_layers: [512, 256, 128]
    activation: relu
    dropout: 0.05


gate:
  hidden_layers: [128, 64]
  activation: relu
  dropout: 0.05

model:
  input_dim: 8        # 这里会被 get_dataloaders 自动覆盖，不用管精确值

training:
  batch_size: 128
  learning_rate: 0.0001
  epochs: 200         # 第二阶段（gate 训练）的最大 epoch
  pretrain_epochs: 100 # 第一阶段专家预训练的 epoch 数
  early_stopping_patience: 20

loss:
  lambda_nonneg: 0.06
  lambda_smooth: 0.03

paths:
  data: data/Water.csv
  save_dir: results/latest
  scaler: results/latest/scaler.pkl

target_col: "Z (-)"
expert_col: "no"
